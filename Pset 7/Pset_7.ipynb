{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 156a - Problem Set 7\n",
    "\n",
    "## Patrone Samuel, 2140749\n",
    "\n",
    "The following notebook is publicly available at https://github.com/spatrone/CS156A-Caltech.git."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems 1-5\n",
    "\n",
    "### Answers: [d] $k=6$, [e] $k=7$, [d] $k=6$, [d] $k=6$, [b] $[0.1,0.2]$\n",
    "### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#import data\n",
    "\n",
    "in_data=pd.read_csv('in.dta',header=None,delim_whitespace=True)\n",
    "out_data=pd.read_csv('out.dta',header=None,delim_whitespace=True)\n",
    "\n",
    "in_pts=in_data[[0, 1]].to_numpy()\n",
    "in_y=in_data[2].to_numpy()\n",
    "\n",
    "out_pts=out_data[[0, 1]].to_numpy()\n",
    "out_y=out_data[2].to_numpy()\n",
    "\n",
    "\n",
    "#non-linear transformation\n",
    "\n",
    "def transform(pts,k):\n",
    "    if(k>7): \n",
    "        raise Exception('WARNING: k must be smaller than 7!')\n",
    "    res=[]\n",
    "    for i in range(len(pts)):\n",
    "        x1=pts[i][0]\n",
    "        x2=pts[i][1]\n",
    "        res_temp=[]\n",
    "        for k in range(k+1):\n",
    "            res_full=[1,x1,x2,x1**2,x2**2,x1*x2,np.abs(x1-x2),np.abs(x1+x2)]\n",
    "            res_temp.append(res_full[k])\n",
    "        res.append(res_temp)\n",
    "    return np.array(res)\n",
    "        \n",
    "def lin_reg(pts,y):\n",
    "    return np.dot(np.linalg.pinv(pts),y)\n",
    "\n",
    "def h(pts,w):\n",
    "    return np.sign(np.dot(w,pts.T))\n",
    "\n",
    "def validation(w,val_pts,val_y):\n",
    "    gout=h(val_pts,w)\n",
    "    testgout=(gout==val_y)\n",
    "    return len(np.where(testgout==False)[0])/len(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 25:10 (training:validation)\n",
      "\n",
      "k=3 | Eval_in: 0.30 | Eval_out: 0.42\n",
      "k=4 | Eval_in: 0.50 | Eval_out: 0.42\n",
      "k=5 | Eval_in: 0.20 | Eval_out: 0.19\n",
      "k=6 | Eval_in: 0.00 | Eval_out: 0.08\n",
      "k=7 | Eval_in: 0.10 | Eval_out: 0.07\n"
     ]
    }
   ],
   "source": [
    "#Problem 1-2-5\n",
    "print('Results for 25:10 (training:validation)\\n')\n",
    "\n",
    "train=in_pts[0:-10]\n",
    "train_y=in_y[0:-10]\n",
    "val=in_pts[25:]\n",
    "val_y=in_y[25:]\n",
    "\n",
    "k=[3,4,5,6,7]\n",
    "\n",
    "for i in k:\n",
    "    train_transf=transform(train,i)\n",
    "    val_in=transform(val,i)\n",
    "    val_out=transform(out_pts,i)\n",
    "    w=lin_reg(train_transf,train_y)\n",
    "    Eval_in=validation(w,val_in,val_y)\n",
    "    Eval_out=validation(w,val_out,out_y)\n",
    "    print(f'k={i} | Eval_in: {Eval_in:.2f} | Eval_out: {Eval_out:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for 10:25 (training:validation)\n",
      "\n",
      "k=3 | Eval_in: 0.28 | Eval_out: 0.40\n",
      "k=4 | Eval_in: 0.36 | Eval_out: 0.39\n",
      "k=5 | Eval_in: 0.20 | Eval_out: 0.28\n",
      "k=6 | Eval_in: 0.08 | Eval_out: 0.19\n",
      "k=7 | Eval_in: 0.12 | Eval_out: 0.20\n"
     ]
    }
   ],
   "source": [
    "#Problem 3-4-5\n",
    "print('Results for 10:25 (training:validation)\\n')\n",
    "\n",
    "val=in_pts[0:-10]\n",
    "val_y=in_y[0:-10]\n",
    "train=in_pts[25:]\n",
    "train_y=in_y[25:]\n",
    "\n",
    "k=[3,4,5,6,7]\n",
    "\n",
    "for i in k:\n",
    "    train_transf=transform(train,i)\n",
    "    val_in=transform(val,i)\n",
    "    val_out=transform(out_pts,i)\n",
    "    w=lin_reg(train_transf,train_y)\n",
    "    Eval_in=validation(w,val_in,val_y)\n",
    "    Eval_out=validation(w,val_out,out_y)\n",
    "    print(f'k={i} | Eval_in: {Eval_in:.2f} | Eval_out: {Eval_out:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "\n",
    "### Answer: [d] $[0.5,0.5,0.4]$\n",
    "\n",
    "### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Nruns=1.0e+06, we find the following average values:\n",
      "\n",
      "[e1,e2,min(e1,e2)]=[0.5,0.5,0.33]\n"
     ]
    }
   ],
   "source": [
    "e1_avg=0\n",
    "e2_avg=0\n",
    "min_avg=0\n",
    "\n",
    "Nruns=1000000\n",
    "\n",
    "for i in range(Nruns):\n",
    "    e1,e2=np.random.rand(),np.random.rand()\n",
    "    e1_avg+=e1\n",
    "    e2_avg+=e2\n",
    "    min_avg+=min(e1,e2)\n",
    "\n",
    "print(f'After Nruns={Nruns:.1e}, we find the following average values:\\n\\n[e1,e2,min(e1,e2)]=[{e1_avg/Nruns:.1f},{e2_avg/Nruns:.1f},{min_avg/Nruns:.2f}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7\n",
    "\n",
    "### Answer: [c] $\\sqrt{9+4\\sqrt{6}}$ \n",
    "\n",
    "### Derivation:\n",
    "\n",
    "In the following, we express the squared error as an analytic function of the variable $\\rho$ using the leave-one-out algorithm with the cross-validation error.\n",
    "\n",
    "Given two points $p_1=(x_1,y_1)$ and $p_2=(x_2,y_2)$, the best fit for the hypothesis set $h_0(x)=b$ is given by the constant line passing in between them, i.e.\n",
    "\n",
    "\\begin{equation}\n",
    "b=\\frac{y_1+y_2}{2}\\,.\n",
    "\\end{equation}\n",
    "\n",
    "For the hypothesis set $h_1(x)=ax+c$, the best fit is given instead by:\n",
    "\n",
    "\\begin{equation}\n",
    " a=\\frac{y_2-y_1}{x_2-x_1}\\\\\n",
    " b=\\frac{y_1 x_2-y_2 x_1}{x_2-x_1}\n",
    "\\end{equation}\n",
    "\n",
    "Hence, for the points $p_1=(-1,0)$, $p_2=(\\rho,1)$ and $p_3=(1,0)$, using the leave-one-out algorithm, we have the following fits:\n",
    "\n",
    "\\begin{equation}\n",
    "p_1,p_2 \\rightarrow b=\\frac{1}{2} \\;\\;\\;\\;  (a,c)=\\left(\\frac{1}{1+\\rho},\\frac{1}{1+\\rho}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "p_1,p_3 \\rightarrow b=0 \\;\\;\\;\\;  (a,c)=\\left(0,0\\right)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "p_2,p_3 \\rightarrow b=\\frac{1}{2} \\;\\;\\;\\;  (a,c)=\\left(\\frac{1}{1-\\rho},\\frac{-1}{1-\\rho}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "The average square error on the left-out-point is therefore:\n",
    "\n",
    "\\begin{equation}\n",
    "E_0=\\frac{1}{2} \\\\\n",
    "E_1=\\frac{1}{3} \\left[1 + \\left(\\frac{4}{1+\\rho}\\right)^2 + \\left(\\frac{4}{1-\\rho}\\right)^2 \\right]\\,.\n",
    "\\end{equation}\n",
    "\n",
    "Solving for $\\rho$ the equation $E_0=E_1$, we find\n",
    "\n",
    "\\begin{equation}\n",
    "\\rho=\\sqrt{9+4\\sqrt{6}}\\,.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems 8-10\n",
    "\n",
    "### Answers: [c] $60 \\%$, [d] $70 \\%$, [b] $3$\n",
    "\n",
    "### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math as m\n",
    "from sklearn import svm\n",
    "\n",
    "def gen_uniform_points(N,d=2,vmin=[-1,-1],vmax=[1,1]):\n",
    "    if(d!=len(vmin)|d!=len(vmax)): \n",
    "        raise Exception('WARNING: Boundary values do not match the dimensionality of the problem!')\n",
    "    pts=np.random.uniform(low=vmin,high=vmax,size=(N,d))\n",
    "    return  np.concatenate((np.ones(N)[:, np.newaxis], pts), axis=1)\n",
    "\n",
    "def gen_line(): \n",
    "    pts=gen_uniform_points(2)\n",
    "    x1,x2=pts[0][1],pts[1][1]\n",
    "    y1,y2=pts[0][2],pts[1][2]\n",
    "    m=(y2-y1)/(x2-x1)\n",
    "    b=(y1*x2-y2*x1)/(x2-x1)\n",
    "    return m,b\n",
    "\n",
    "def line(x,m,b):\n",
    "    return x*m+b\n",
    "\n",
    "def h(w,data):\n",
    "    return np.sign(np.dot(w,data.T))\n",
    "\n",
    "def label_linear(pts,m,b):\n",
    "    return np.array([np.sign(pts[i][2]-(m*pts[i][1]+b)) for i in range(len(pts))])\n",
    "\n",
    "def color_pts(label):\n",
    "    #green is +1, red is -1\n",
    "    col=[]\n",
    "    for i in range(len(label)):\n",
    "        if(label[i]>0): col.append('green')\n",
    "        else: col.append('red')\n",
    "    return col\n",
    "\n",
    "def Eout(m,b,w,Nval=1000):\n",
    "    pts=gen_uniform_points(Nval)\n",
    "    true=label_linear(pts,m,b)\n",
    "    g=h(w,pts)\n",
    "    testg=(g==true)\n",
    "    Eout=len(np.where(testg==False)[0])\n",
    "    return Eout/Nval\n",
    "\n",
    "def PLA(pts,y,plot=False):\n",
    "    \n",
    "    #initialization before learning\n",
    "    w=np.zeros(3)\n",
    "    converged=False\n",
    "    iterations=0\n",
    "    \n",
    "    #learning algorithm\n",
    "    while(converged==False):\n",
    "        g=h(w,pts)\n",
    "        testg=(g==y)\n",
    "        misclassified=np.where(testg==False)[0]\n",
    "        if(len(misclassified)>0):\n",
    "            j=np.random.randint(len(misclassified))\n",
    "            i=misclassified[j]\n",
    "            w+=y[i]*pts[i]\n",
    "            iterations+=1\n",
    "        g=h(w,pts)\n",
    "        converged=np.all(g==y)\n",
    "    \n",
    "    if(plot==True):\n",
    "        x=np.linspace(-1,1,100)\n",
    "        col=color_pts(y)\n",
    "        plt.scatter(pts[:,1],pts[:,2],color=col)\n",
    "        plt.plot(x,line(x,-w[1]/w[2],-w[0]/w[2]),color='blue',linestyle='dashed')\n",
    "        plt.xlim([-1, 1])\n",
    "        plt.ylim([-1, 1])\n",
    "    return w, iterations\n",
    "\n",
    "def SVM(pts,y,plot=False):\n",
    "    clf = svm.SVC(C=np.Inf, kernel='linear', cache_size=20000)\n",
    "    clf.fit(pts[:,1:3], y)\n",
    "    w=clf.coef_[0]\n",
    "    w=np.append(clf.intercept_[0],w)\n",
    "    if(plot==True):\n",
    "        x=np.linspace(-1,1,100)\n",
    "        plt.plot(x,line(x,-w[1]/w[2],-w[0]/w[2]),color='blue')\n",
    "    return w,sum(clf.n_support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Npts=10, averaged over Nruns=1000, SVM performs better than PLA 60% of the times!\n"
     ]
    }
   ],
   "source": [
    "Npts=10\n",
    "Nruns=1000\n",
    "\n",
    "out_perf=0\n",
    "for i in range(Nruns):\n",
    "    check=True\n",
    "    while(check==True):\n",
    "        pts=gen_uniform_points(Npts)\n",
    "        m,b=gen_line()\n",
    "        y=label_linear(pts,m,b)\n",
    "        check=(np.abs(np.sum(y))==Npts)\n",
    "    wp,it=PLA(pts,y)\n",
    "    ws,vec=SVM(pts,y)\n",
    "    if(Eout(m,b,wp)>Eout(m,b,ws)): out_perf+=1\n",
    "\n",
    "print(f\"With Npts={Npts}, averaged over Nruns={Nruns}, SVM performs better than PLA {out_perf/10:.0f}% of the times!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Npts=100, averaged over Nruns=1000, SVM performs better than PLA 61% of the times!\n",
      "The average number of support vectors is 3\n"
     ]
    }
   ],
   "source": [
    "Npts=100\n",
    "Nruns=1000\n",
    "\n",
    "out_perf=0\n",
    "vec=0\n",
    "for i in range(Nruns):\n",
    "    check=True\n",
    "    while(check==True):\n",
    "        pts=gen_uniform_points(Npts)\n",
    "        m,b=gen_line()\n",
    "        y=label_linear(pts,m,b)\n",
    "        check=(np.abs(np.sum(y))==Npts)\n",
    "    wp,it=PLA(pts,y)\n",
    "    ws,vec_run=SVM(pts,y)\n",
    "    vec+=vec_run\n",
    "    if(Eout(m,b,wp)>Eout(m,b,ws)): out_perf+=1\n",
    "\n",
    "print(f\"With Npts={Npts}, averaged over Nruns={Nruns}, SVM performs better than PLA {out_perf/10:.0f}% of the times!\\nThe average number of support vectors is {vec/Nruns:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": false,
   "autoclose": true,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": true,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
